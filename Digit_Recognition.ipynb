{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa4tIQ/COKcKQ4fffhKcFT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssupsandeep/Nerural-networks-and-deep-learning/blob/main/Digit_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Double Digit Recognition\n"
      ],
      "metadata": {
        "id": "Trbl6RyU-Dd2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "ufVwIi4mDSUH",
        "outputId": "7fc85a55-bcd9-4cc7-cfb3-98f12408ddf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 114ms/step - left_digit_accuracy: 0.8538 - left_digit_loss: 0.4676 - loss: 0.9444 - right_digit_accuracy: 0.8465 - right_digit_loss: 0.4768 - val_left_digit_accuracy: 0.9817 - val_left_digit_loss: 0.0638 - val_loss: 0.1448 - val_right_digit_accuracy: 0.9743 - val_right_digit_loss: 0.0809\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 112ms/step - left_digit_accuracy: 0.9808 - left_digit_loss: 0.0605 - loss: 0.1182 - right_digit_accuracy: 0.9815 - right_digit_loss: 0.0577 - val_left_digit_accuracy: 0.9825 - val_left_digit_loss: 0.0573 - val_loss: 0.1085 - val_right_digit_accuracy: 0.9872 - val_right_digit_loss: 0.0511\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 119ms/step - left_digit_accuracy: 0.9871 - left_digit_loss: 0.0411 - loss: 0.0738 - right_digit_accuracy: 0.9896 - right_digit_loss: 0.0327 - val_left_digit_accuracy: 0.9862 - val_left_digit_loss: 0.0504 - val_loss: 0.1035 - val_right_digit_accuracy: 0.9858 - val_right_digit_loss: 0.0531\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 111ms/step - left_digit_accuracy: 0.9910 - left_digit_loss: 0.0271 - loss: 0.0475 - right_digit_accuracy: 0.9937 - right_digit_loss: 0.0204 - val_left_digit_accuracy: 0.9870 - val_left_digit_loss: 0.0441 - val_loss: 0.0806 - val_right_digit_accuracy: 0.9892 - val_right_digit_loss: 0.0363\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 108ms/step - left_digit_accuracy: 0.9932 - left_digit_loss: 0.0202 - loss: 0.0332 - right_digit_accuracy: 0.9952 - right_digit_loss: 0.0130 - val_left_digit_accuracy: 0.9883 - val_left_digit_loss: 0.0430 - val_loss: 0.0826 - val_right_digit_accuracy: 0.9883 - val_right_digit_loss: 0.0394\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Imports\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load MNIST dataset\n",
        "\n",
        "# x_train, x_test: images (28x28 grayscale)\n",
        "# y_train, y_test: digit labels (0–9)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Create double-digit images\n",
        "\n",
        "def create_double_digit(images, labels):\n",
        "    \"\"\"\n",
        "    Creates images with two digits side-by-side.\n",
        "    Returns:\n",
        "        X  -> combined images (28x56x1)\n",
        "        y1 -> left digit labels\n",
        "        y2 -> right digit labels\n",
        "    \"\"\"\n",
        "    X, y1, y2 = [], [], []\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        # Randomly choose a second image\n",
        "        j = np.random.randint(0, len(images))\n",
        "\n",
        "        # Concatenate images horizontally (left + right)\n",
        "        img = np.concatenate([images[i], images[j]], axis=1)\n",
        "        X.append(img)\n",
        "\n",
        "        # Store labels for each digit\n",
        "        y1.append(labels[i])\n",
        "        y2.append(labels[j])\n",
        "\n",
        "    # Convert to NumPy array and add channel dimension\n",
        "    X = np.array(X)[..., np.newaxis]\n",
        "\n",
        "    return X, np.array(y1), np.array(y2)\n",
        "\n",
        "# Generate training and testing data\n",
        "X_train, y_left_train, y_right_train = create_double_digit(x_train, y_train)\n",
        "X_test, y_left_test, y_right_test = create_double_digit(x_test, y_test)\n",
        "\n",
        "\n",
        "# Build the CNN model\n",
        "\n",
        "inputs = layers.Input(shape=(28, 56, 1))  # Two MNIST digits side by side\n",
        "\n",
        "# First convolution block\n",
        "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "\n",
        "# Second convolution block\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "\n",
        "# Fully connected layers\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "# Output heads (multi-output model)\n",
        "left = layers.Dense(10, activation='softmax', name='left_digit')(x)\n",
        "right = layers.Dense(10, activation='softmax', name='right_digit')(x)\n",
        "\n",
        "# Define the model\n",
        "model = models.Model(inputs, [left, right])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        'left_digit': 'sparse_categorical_crossentropy',\n",
        "        'right_digit': 'sparse_categorical_crossentropy'\n",
        "    },\n",
        "    metrics={\n",
        "        'left_digit': 'accuracy',\n",
        "        'right_digit': 'accuracy'\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(\n",
        "    X_train,\n",
        "    {\n",
        "        'left_digit': y_left_train,\n",
        "        'right_digit': y_right_train\n",
        "    },\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "\n",
        "# Test on one image\n",
        "\n",
        "idx = 0  # Change index to test different samples\n",
        "image = X_test[idx:idx+1]\n",
        "\n",
        "# Predict both digits\n",
        "pred_left, pred_right = model.predict(image)\n",
        "\n",
        "# Convert probabilities to digit predictions\n",
        "d1 = np.argmax(pred_left)\n",
        "d2 = np.argmax(pred_right)\n",
        "\n",
        "# Combine digits into a two-digit number\n",
        "predicted_digit = d1 * 10 + d2\n",
        "\n",
        "\n",
        "# Display result\n",
        "plt.imshow(image[0].squeeze(), cmap='gray')\n",
        "plt.title(f\"Predicted Digit: {predicted_digit}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow matplotlib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values (0–255 → 0–1)\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Add channel dimension (required for CNN)\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # 10 digits (0–9)\n",
        "])\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1\n",
        ")\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", test_accuracy)\n",
        "import numpy as np\n",
        "\n",
        "# Pick a random test image\n",
        "index = 0\n",
        "image = x_test[index]\n",
        "\n",
        "prediction = model.predict(image[np.newaxis, ...])\n",
        "predicted_digit = np.argmax(prediction)\n",
        "\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"Predicted Digit: {predicted_digit}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L-QZPEg8_Dig",
        "outputId": "f0d3702b-cfb8-4707-da70-8fa46b2a9a0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 52ms/step - accuracy: 0.8840 - loss: 0.3942 - val_accuracy: 0.9845 - val_loss: 0.0522\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9818 - loss: 0.0565 - val_accuracy: 0.9843 - val_loss: 0.0524\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 49ms/step - accuracy: 0.9882 - loss: 0.0374 - val_accuracy: 0.9895 - val_loss: 0.0376\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - accuracy: 0.9920 - loss: 0.0254 - val_accuracy: 0.9887 - val_loss: 0.0361\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - accuracy: 0.9940 - loss: 0.0190 - val_accuracy: 0.9918 - val_loss: 0.0330\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0360\n",
            "Test accuracy: 0.9912999868392944\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEmBJREFUeJzt3H+slnX5wPHrwEHBAyrSwVAUSEMqYOipZsMCC5AOsjZlheUEVsQaIc6itdwC1MJ+zFAhWmuTfmAUa1YzoqCAMsqVEgOSEILUUYmDFAyGBz7fPxzXFwT03EfOOQqv18YfPM99PffHs3refO7nOXdNKaUEAEREh/ZeAACvH6IAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKJAm+vbt29MnDgx/75q1aqoqamJVatWtduaXu7lazxZtm/fHjU1NbFw4cIWzdfU1MSsWbNO6prgSKJwmlm4cGHU1NTkn86dO0f//v3j05/+dPznP/9p7+VVsnTp0nZ/gzzyZ1lbWxvnnXdeNDQ0xPTp0+Nvf/tbq59/zZo1MWvWrPjvf//b4tc4HKoT/Zk8efLJWzCve7XtvQDax+233x79+vWL/fv3x8MPPxwLFiyIpUuXxoYNG+Kss85q07W8733vi3379sUZZ5xRaW7p0qUxf/78dg/DyJEj46abbopSSjz33HOxbt26+O53vxvf/OY34ytf+UrceuuteWyfPn1i37590alTpxada9++fVFb+///t12zZk3Mnj07Jk6cGOeee26LXrO+vj6+//3vH/P4smXLYtGiRTFq1KgWvS5vTKJwmvrgBz8Y73znOyMi4hOf+ET06NEj7r777vjZz34WN9xww3FnXnjhhairqzvpa+nQoUN07tz5pL9uW+nfv3/ceOONRz121113xdixY+Mzn/lMDBgwIBobGyMicnfWUq3xc6qrqztm/REv7SrPPvvsGDt27Ek/J69fLh8RERHvf//7IyJi27ZtERExceLE6Nq1a2zdujUaGxujW7du8bGPfSwiIg4dOhRz586Nd7zjHdG5c+c4//zzY8qUKbF79+6jXrOUEnfeeWf07t07zjrrrLj66qtj48aNx5z7RJ8pPPLII9HY2Bjdu3ePurq6GDx4cNxzzz25vvnz50fE0ZdwDjvZa6yqR48esXjx4qitrY0vfelL+fiJPlNYsmRJvP3tb4/OnTvHwIED48EHH4yJEydG3759jzruyM8UZs2aFTNmzIiIiH79+uXPYPv27RER8eyzz8amTZvif//7X+X1/+tf/4qVK1fGdddd94YONtXZKRAREVu3bo2Il97MDmtqaoprrrkmrrrqqvj617+el5WmTJkSCxcujEmTJsXNN98c27Zti3nz5sXatWvjD3/4Q14a+eIXvxh33nlnNDY2RmNjYzz22GMxatSoOHDgwKuuZ/ny5XHttddGr169Yvr06fHmN785Hn/88XjooYdi+vTpMWXKlNixY0csX778uJc+2mKNr+biiy+OYcOGxcqVK+P555+Ps88++7jH/eIXv4iPfOQjMWjQoJgzZ07s3r07Pv7xj8eFF174iq9/3XXXxebNm+OHP/xhfOMb34g3velNEfHS5aCIiHnz5sXs2bNj5cqVMXz48EprX7x4cRw6dCj/IcBppHBauf/++0tElBUrVpSdO3eWp556qixevLj06NGjdOnSpTz99NOllFImTJhQIqJ8/vOfP2r+97//fYmIsmjRoqMeX7Zs2VGPP/PMM+WMM84oY8aMKYcOHcrjvvCFL5SIKBMmTMjHVq5cWSKirFy5spRSSlNTU+nXr1/p06dP2b1791HnOfK1pk6dWo73P+HWWOOJRESZOnXqCZ+fPn16iYiybt26Ukop27ZtKxFR7r///jxm0KBBpXfv3mXPnj352KpVq0pElD59+hxzvpkzZ+bfv/a1r5WIKNu2bTvm3DNnzjzq51pFQ0ND6dWrVzl48GDlWd7YXD46TY0YMSLq6+vjoosuivHjx0fXrl3jwQcfPOZfp5/61KeO+vuSJUvinHPOiZEjR8azzz6bfxoaGqJr166xcuXKiIhYsWJFHDhwIKZNm3bUZZ1bbrnlVde2du3a2LZtW9xyyy3HfHh65GudSFussbm6du0aERF79uw57vM7duyI9evXx0033ZTHRkQMGzYsBg0a9JrOPWvWrCilVN4lbN68OR599NEYP358dOjgLeJ04/LRaWr+/PnRv3//qK2tjfPPPz8uu+yyY94Aamtro3fv3kc99sQTT8Rzzz0XPXv2PO7rPvPMMxER8c9//jMiIt761rce9Xx9fX107979Fdd2+FLWwIEDm/8f1MZrbK69e/dGRES3bt2O+/zhNVx66aXHPHfppZfGY489dlLWUcWiRYsiIlw6Ok2Jwmnq3e9+d3776ETOPPPMY0Jx6NCh6NmzZ75xvNzh69nt6fW0xg0bNkTHjh2jX79+bXbO1+qBBx6Iyy67LBoaGtp7KbQDUaCSSy65JFasWBFDhw6NLl26nPC4Pn36RMRL/2p/y1veko/v3LnzmG8AHe8cES+9oY4YMeKEx53oUlJbrLE5nnzyyVi9enW85z3vOeFO4fAatmzZcsxzx3vs5ZpzOa2KRx55JLZs2RK33377SX1d3jhcMKSSD3/4w3Hw4MG44447jnmuqakpf7N2xIgR0alTp7jvvvuilJLHzJ0791XPccUVV0S/fv1i7ty5x/ym7pGvdfh3Jl5+TFus8dXs2rUrbrjhhjh48GDcdtttJzzuggsuiIEDB8b3vve9vNQUEbF69epYv379q57nRD+DiJZ9JfWBBx6IiIiPfvSjzZ7h1GKnQCXDhg2LKVOmxJw5c+Kvf/1rjBo1Kjp16hRPPPFELFmyJO65554YN25c1NfXx2c/+9mYM2dOXHvttdHY2Bhr166NX/7yl/nVyRPp0KFDLFiwIMaOHRtDhgyJSZMmRa9evWLTpk2xcePG+NWvfhURkZc3br755rjmmmuiY8eOMX78+DZZ45E2b94cP/jBD6KUEs8//3ysW7culixZEnv37o277747Ro8e/YrzX/7yl+NDH/pQDB06NCZNmhS7d++OefPmxcCBA48KxfEc/hncdtttMX78+OjUqVOMHTs26urqKn8l9eDBg/GjH/0orrzyytytcRpq1+8+0eYOfyX1z3/+8yseN2HChFJXV3fC57/97W+XhoaG0qVLl9KtW7cyaNCg8rnPfa7s2LEjjzl48GCZPXt26dWrV+nSpUsZPnx42bBhQ+nTp88rfiX1sIcffriMHDmydOvWrdTV1ZXBgweX++67L59vamoq06ZNK/X19aWmpuaYr6eezDWeSETknw4dOpRzzz23XH755WX69Oll48aNxxx/vK+kllLK4sWLy4ABA8qZZ55ZBg4cWH7+85+X66+/vgwYMOCY8x35ldRSSrnjjjvKhRdeWDp06HDU11OrfiX18Fd277333mYdz6mpppQj9s3A68aQIUOivr4+li9f3t5L4TTiMwVoZy+++GI0NTUd9diqVati3bp1lX/HAF4rOwVoZ9u3b48RI0bEjTfeGBdccEFs2rQpvvWtb8U555wTGzZsOOrWI9DafNAM7ax79+7R0NAQ3/nOd2Lnzp1RV1cXY8aMibvuuksQaHN2CgAknykAkEQBgNTszxRO9q/TA9C2mvNpgZ0CAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAECqbe8FnA7GjRtXeWby5MktOteOHTsqz+zfv7/yzKJFiyrP/Pvf/648ExGxZcuWFs0B1dkpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAqaaUUpp1YE1Na6/llPWPf/yj8kzfvn1P/kLa2Z49e1o0t3HjxpO8Ek62p59+uvLMV7/61Rad6y9/+UuL5ohoztu9nQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFJtey/gdDB58uTKM4MHD27RuR5//PHKM29729sqz1xxxRWVZ4YPH155JiLiyiuvrDzz1FNPVZ656KKLKs+0paampsozO3furDzTq1evyjMt8eSTT7Zozg3xWpedAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUk0ppTTrwJqa1l4Lp7ju3bu3aG7IkCGVZx599NHKM+9617sqz7Sl/fv3V57ZvHlz5ZmW3FTxvPPOqzwzderUyjMREQsWLGjRHBHNebu3UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQHJDPDiFXX/99ZVnfvzjH1ee2bBhQ+WZq6++uvJMRMSuXbtaNIcb4gFQkSgAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACC5Syq8QfTs2bPyzPr169vkPOPGjas885Of/KTyDK+Nu6QCUIkoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCk2vZeANA8U6dOrTxTX19feWb37t2VZ/7+979XnuH1yU4BgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpppRSmnVgTU1rrwVOC0OHDm3R3G9/+9vKM506dao8M3z48Mozv/vd7yrP0Paa83ZvpwBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgFTb3guA001jY2OL5lpyc7vf/OY3lWf++Mc/Vp7h1GGnAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA5IZ48Bp06dKl8szo0aNbdK4DBw5Unpk5c2blmRdffLHyDKcOOwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACC5Syq8BjNmzKg8c/nll7foXMuWLas8s2bNmhadi9OXnQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFJNKaU068CamtZeC7SrMWPGVJ756U9/WnnmhRdeqDwTETF69OjKM3/6059adC5OTc15u7dTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAqm3vBUBr6NGjR+WZe++9t/JMx44dK88sXbq08kyEm9vRNuwUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQakoppVkH1tS09lrguFpy07mW3DyuoaGh8szWrVsrz4wePbryTEvPBUdqztu9nQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFJtey8AXs0ll1xSeaYlN7driVtvvbXyjBvb8XpmpwBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACR3SaXN9OnTp0Vzv/71r0/ySo5vxowZlWceeuihVlgJtB87BQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJDfEo8188pOfbNHcxRdffJJXcnyrV6+uPFNKaYWVQPuxUwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQHJDPFrkqquuqjwzbdq0VlgJcDLZKQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAILkhHi3y3ve+t/JM165dW2Elx7d169bKM3v37m2FlcAbi50CAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQ3CWV171169ZVnvnABz5QeWbXrl2VZ+BUY6cAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYBUU0opzTqwpqa11wJAK2rO272dAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUm1zD2zmffMAeAOzUwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAg/R8fVebwM9dKzAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}